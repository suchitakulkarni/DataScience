{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658e80c2-2f48-4455-b579-176efec759a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is obtained from https://www.kaggle.com/datasets/ishikajohari/taylor-swift-all-lyrics-30-albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ac913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbe52ad-e740-4a63-a044-9b3863a64ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baafe01-d4e6-4aec-956a-0bd13184855e",
   "metadata": {},
   "source": [
    "# Data cleanning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7dc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_albums(df):\n",
    "    substring = ['Deluxe','Disney', 'Live','Stadium','delux','International','Piano'\\\n",
    "                 , 'Version', 'anthology', '3am', 'Dawn',\"Cruelest\",'Japanese','Albatross',\\\n",
    "                 'Remixes','dropped','Exclusive','digitally','Bolter','Black','Afraid','Cassandra'\\\n",
    "                 ,'sweetest','Carolina','ladies','Chapter','ANTHOLOGY','Night']\n",
    "    pattern = '|'.join(substring)\n",
    "\n",
    "    filter = df['Albums'].str.contains(pattern) \n",
    "    filtered_df = df[~filter]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe394299",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/suchitakulkarni/Dropbox/private/job_applications/industry/GenAI_course/Taylor_lyrics/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d34bf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(os.path.join(datapath,'Albums.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7671c360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Albums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>758025</td>\n",
       "      <td>Speak Now (Taylor’s Version)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040217</td>\n",
       "      <td>Midnights (The Late Night Edition)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1040211</td>\n",
       "      <td>Midnights (The Til Dawn Edition)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027134</td>\n",
       "      <td>folklore: the long pond studio sessions (Recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1013719</td>\n",
       "      <td>The More Red (Taylor’s Version) Chapter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             Albums\n",
       "0   758025                       Speak Now (Taylor’s Version)\n",
       "1  1040217                 Midnights (The Late Night Edition)\n",
       "2  1040211                   Midnights (The Til Dawn Edition)\n",
       "3  1027134  folklore: the long pond studio sessions (Recor...\n",
       "4  1013719            The More Red (Taylor’s Version) Chapter"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8838a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10                        Midnights\n",
      "30                     Taylor Swift\n",
      "31      Fearless (Platinum Edition)\n",
      "33                              Red\n",
      "34                             1989\n",
      "35                       Reputation\n",
      "36                            Lover\n",
      "37                         Folklore\n",
      "38                         Evermore\n",
      "39                        Speak Now\n",
      "55    THE TORTURED POETS DEPARTMENT\n",
      "Name: Albums, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(filter_albums(df)['Albums'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c4543-ed60-4dfa-9181-1405347e5632",
   "metadata": {},
   "source": [
    "## Lyrical retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0a4b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Album           Song_Name\n",
      "0    Midnights        MidnightRain\n",
      "1    Midnights              Maroon\n",
      "2    Midnights           Labyrinth\n",
      "3    Midnights  YoureOnYourOwn_Kid\n",
      "4    Midnights      SnowOnTheBeach\n",
      "..         ...                 ...\n",
      "109   Evermore      longstoryshort\n",
      "110   Evermore            goldrush\n",
      "111   Evermore      nobody_nocrime\n",
      "112   Evermore   champagneproblems\n",
      "113   Evermore         coneyisland\n",
      "\n",
      "[114 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "song_text = []\n",
    "song_names_list = []\n",
    "i = 0\n",
    "album_song_df = pd.DataFrame(columns = ['Album', 'Song_Name'])\n",
    "for an_album in filter_albums(df)['Albums'].tolist():\n",
    "    album_path = os.path.join(datapath,'Albums', an_album)\n",
    "    if os.path.exists(album_path): \n",
    "        song_names = os.listdir(album_path)\n",
    "        \n",
    "        for name in song_names:\n",
    "            album_song_df.loc[i] = [an_album, name.replace(\".txt\", '')]\n",
    "            song_names_list.append(name.replace(\".txt\", ''))\n",
    "            song_path = os.path.join(album_path,name)\n",
    "            \n",
    "            f = open(song_path, \"r\")\n",
    "            s = f.read()\n",
    "            s_begin = s[s.find('Lyrics'):]\n",
    "            s_end = s_begin[:s_begin.find('Embed')]\n",
    "            s_cleaned = s_end[:-2]    \n",
    "            song_text.append(s_cleaned)\n",
    "            i += 1\n",
    "print(album_song_df)\n",
    "album_song_df.to_csv('album_songnames.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f0178-2d18-4c90-a7f5-ab58ad1ec1f2",
   "metadata": {},
   "source": [
    "# Testing GenAI concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c2105-5516-42df-9e6f-4132b81bbc23",
   "metadata": {},
   "source": [
    "### Recommendation using sentence embeddings "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d356b90-1974-4870-9944-bf36e5f83491",
   "metadata": {},
   "source": [
    "This embeds at the sentence level, retrieves songs which have 'similar' text, using cosine similarity. This uses concepts taught in RAG phase of the course. The final answer is generated on the basis of the documents provided and a LLM used. Retrieval bases on augmented generation --> Retrieval Augmented Generation. Please note the use of 'SentenceTransformer' in the load_model method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a807023f-59f3-4b9a-9f78-5433a009aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:21:28.550 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "@st.cache_data\n",
    "def get_embeddings(texts):\n",
    "    model = load_model()\n",
    "    return model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e48c5f-4262-4482-9bff-fb2efc2b8cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:21:34.994 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-06-14 19:21:35.001 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-14 19:21:35.338 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/genai/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-14 19:21:35.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-14 19:21:35.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-14 19:21:35.844 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-14 19:21:35.846 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebe3131dbb94719abc416645c7b7d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 19:21:43.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-14 19:21:43.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embeddings(song_text)\n",
    "np.save(f\"Taylor_song_lyrics_embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab206a0a-b05e-4abb-b947-2552a27bea5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a462aa76-5c39-40d2-9f12-d3aab6cf1819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen song is MidnightRain from album Midnights\n",
      "Closest song is marjorie from album Evermore\n",
      "Closest song is ItsNicetoHaveaFriend from album Lover\n",
      "Closest song is madwoman from album Folklore\n",
      "Closest song is evermore from album Evermore\n",
      "Closest song is dorothea from album Evermore\n",
      "Closest song is tolerateit from album Evermore\n",
      "Closest song is thisismetrying from album Folklore\n",
      "Closest song is ThisLove from album 1989\n",
      "Closest song is ivy from album Evermore\n",
      "Closest song is Starlight from album Red\n",
      "Closest song is IForgotThatYouExisted from album Lover\n",
      "Closest song is Maroon from album Midnights\n"
     ]
    }
   ],
   "source": [
    "load_data = np.load(f\"Taylor_song_lyrics_embeddings.npy\")\n",
    "load_data_frame = pd.read_csv(\"album_songnames.csv\")\n",
    "chosen_song = 0\n",
    "similarities = cosine_similarity([load_data[chosen_song]], load_data)[0]\n",
    "print(f\"Chosen song is {load_data_frame['Song_Name'][chosen_song]} from album {load_data_frame['Album'][chosen_song]}\")\n",
    "for item in np.argsort(similarities)[::10]:\n",
    "    print(f\"Closest song is {load_data_frame['Song_Name'][item]} from album {load_data_frame['Album'][item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b26e36-9fe9-4608-834a-cc2974cbf861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your chosen song is YoureOnYourOwn_Kid\n",
      "Closest song is Reputation_Prologue_ from album Reputation\n",
      "Closest song is EverythingHasChanged from album Red\n",
      "Closest song is Starlight from album Red\n",
      "Closest song is SnowOnTheBeach from album Midnights\n",
      "Closest song is MidnightRain from album Midnights\n",
      "Closest song is willow from album Evermore\n",
      "Closest song is DontBlameMe from album Reputation\n",
      "Closest song is CorneliaStreet from album Lover\n",
      "Closest song is Daylight from album Lover\n",
      "Closest song is thisismetrying from album Folklore\n",
      "Closest song is cardigan from album Folklore\n",
      "Closest song is peace from album Folklore\n"
     ]
    }
   ],
   "source": [
    "load_data = np.load(f\"Taylor_song_lyrics_embeddings.npy\")\n",
    "\n",
    "chosen_song = 3\n",
    "print(f\"your chosen song is {song_names_list[chosen_song]}\")\n",
    "similarities = cosine_similarity([embeddings[chosen_song]], embeddings)[0]\n",
    "for item in np.argsort(similarities)[::10]:\n",
    "    print(f\"Closest song is {album_song_df['Song_Name'][item]} from album {album_song_df['Album'][item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc26bf-e6a3-4a16-b8de-d5660d8c7691",
   "metadata": {},
   "source": [
    "## Converting song names in understandable dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339bd43c-6823-487c-aa6a-f9edc86b0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\") \n",
    "\n",
    "def few_shot_song_name_formatter(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Format the name of song into human understandble form. Provide your best guess.\n",
    "        \n",
    "        Examples:\n",
    "        Text: MidnightRain\n",
    "        Formatted name: Midnight Rain\n",
    "        \n",
    "        Text: SoItGoes___\n",
    "        Formatted name: So It Goes\n",
    "\n",
    "        Text: Maroon\n",
    "        Formatted name: Maroon\n",
    "        \n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Formatted name:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    result = result.strip()\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2733f0-809a-434b-b171-6bdf3bd7e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midnight Rain\n",
      "Maroon\n",
      "Labyrinth\n",
      "You're On Your Own Kid\n",
      "Snow On The Beach\n",
      "Question\n",
      "Vigilante Shit\n",
      "Karma\n",
      "Formatted name\n",
      "Sweet Nothing\n",
      "Bejeweled\n",
      "Formatted name\n",
      "Anti Hero\n",
      "Mastermind\n",
      "Lavender Haze\n",
      "Come Back Be Here\n",
      "I Almost Do\n",
      "Treacherous\n",
      "The Last Time\n",
      "All Too Well\n",
      "State of Grace\n",
      "Stay Stay Stay\n",
      "Everything Has Changed\n",
      "Starlight\n",
      "Formatted name\n",
      "The Lucky One\n",
      "Holy Ground\n",
      "WeAreNeverEverGettingBackTogether\n",
      "\n",
      "Formatted name\n",
      "Red\n",
      "Sad Beautiful Tragic\n",
      "Begin Again\n",
      "I Knew You Were Trouble\n",
      "22 (or Twenty-Two) \n",
      "\n",
      "Since \"22\" is a number, it can be either written as is or spelled out as \"Twenty-Two\". Without more context, it's difficult to determine which format is more suitable. However, in the context of song titles, it's common to see numbers written as is, so \"22\" is a reasonable choice.\n",
      "Girl at Home\n",
      "The Moment I Knew\n",
      "Bad Blood\n",
      "Blank Space\n",
      "I Know Places\n",
      "This Love\n",
      "Out Of The Woods\n",
      "Formatted name\n",
      "Welcome to New York\n",
      "All You Had to Do Was Stay\n",
      "Shake It Off\n",
      "Style\n",
      "1989 Booklet\n",
      "I Wish You Would\n",
      "Clean\n",
      "How You Get The Girl\n",
      "I Did Something Bad\n",
      "Ready for It\n",
      "Delicate\n",
      "Don't Blame Me\n",
      "Why She Disappeared Poem\n",
      "Look What You Made Me Do\n",
      "End Game\n",
      "Call It What You Want\n",
      "New Year's Day\n",
      "Gorgeous\n",
      "Getaway Car\n",
      "Text\n",
      "Dress\n",
      "King of My Heart\n",
      "Dancing With Our Hands Tied\n",
      "So It Goes\n",
      "Reputation Prologue\n",
      "If You're Anything Like Me Poem\n",
      "This Is Why We Can't Have Nice Things\n",
      "It's Nice to Have a Friend\n",
      "Me\n",
      "Cornelia Street\n",
      "You Need To Calm Down\n",
      "The Man\n",
      "Lover\n",
      "The Archer\n",
      "Death by a Thousand Cuts\n",
      "Paper Rings\n",
      "Afterglow\n",
      "Formatted name\n",
      "Soon You'll Get Better\n",
      "I Forgot That You Existed\n",
      "Daylight\n",
      "Formatted name\n",
      "Miss Americana The Heartbreak Prince\n",
      "Cruel Summer\n",
      "London Boy\n",
      "False God\n",
      "I Think He Knows\n",
      "The Last Great American Dynasty\n",
      "This Is Me Trying\n",
      "Epiphany\n",
      "My Tears Ricochet\n",
      "Exile\n",
      "Mirror Ball\n",
      "seven\n",
      "Formatted name\n",
      "Peace\n",
      "The 1\n",
      "\n",
      "However, considering it's likely a song title, a more plausible formatted name could be\n",
      "Cardigan\n",
      "Betty\n",
      "Invisible String\n",
      "August\n",
      "Hoax\n",
      "Mad Woman\n",
      "Illicit Affairs\n",
      "This Is The Damn Season\n",
      "Evermore\n",
      "Happiness\n",
      "Tolerate It\n",
      "Willow\n",
      "Marjorie\n",
      "Ivy\n",
      "Dorothea\n",
      "Closure\n",
      "Cowboy Like Me\n",
      "Long Story Short\n",
      "Gold Rush\n",
      "Nobody No Crime\n",
      "Champagne Problems\n",
      "Coney Island\n"
     ]
    }
   ],
   "source": [
    "formatted_name = []\n",
    "for sname in song_names_list: \n",
    "    result_name = few_shot_song_name_formatter(sname)\n",
    "    print(result_name)\n",
    "    formatted_name.append(result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a282ab-4585-41db-abbf-571606527a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "formatted_name_safecopy = copy.deepcopy(formatted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e91002db-fcbb-434a-9783-a7a6d09457bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Midnight Rain',\n",
       " 'Maroon',\n",
       " 'Labyrinth',\n",
       " \"You're On Your Own Kid\",\n",
       " 'Snow On The Beach',\n",
       " 'Question',\n",
       " 'Vigilante Shit',\n",
       " 'Karma\\nFormatted name',\n",
       " 'Sweet Nothing',\n",
       " 'Bejeweled\\nFormatted name',\n",
       " 'Anti Hero',\n",
       " 'Mastermind',\n",
       " 'Lavender Haze',\n",
       " 'Come Back Be Here',\n",
       " 'I Almost Do',\n",
       " 'Treacherous',\n",
       " 'The Last Time',\n",
       " 'All Too Well',\n",
       " 'State of Grace',\n",
       " 'Stay Stay Stay',\n",
       " 'Everything Has Changed',\n",
       " 'Starlight\\nFormatted name',\n",
       " 'The Lucky One',\n",
       " 'Holy Ground',\n",
       " 'WeAreNeverEverGettingBackTogether\\n\\nFormatted name',\n",
       " 'Red',\n",
       " 'Sad Beautiful Tragic',\n",
       " 'Begin Again',\n",
       " 'I Knew You Were Trouble',\n",
       " '22 (or Twenty-Two) \\n\\nSince \"22\" is a number, it can be either written as is or spelled out as \"Twenty-Two\". Without more context, it\\'s difficult to determine which format is more suitable. However, in the context of song titles, it\\'s common to see numbers written as is, so \"22\" is a reasonable choice.',\n",
       " 'Girl at Home',\n",
       " 'The Moment I Knew',\n",
       " 'Bad Blood',\n",
       " 'Blank Space',\n",
       " 'I Know Places',\n",
       " 'This Love',\n",
       " 'Out Of The Woods',\n",
       " 'Formatted name',\n",
       " 'Welcome to New York',\n",
       " 'All You Had to Do Was Stay',\n",
       " 'Shake It Off',\n",
       " 'Style',\n",
       " '1989 Booklet',\n",
       " 'I Wish You Would',\n",
       " 'Clean',\n",
       " 'How You Get The Girl',\n",
       " 'I Did Something Bad',\n",
       " 'Ready for It',\n",
       " 'Delicate',\n",
       " \"Don't Blame Me\",\n",
       " 'Why She Disappeared Poem',\n",
       " 'Look What You Made Me Do',\n",
       " 'End Game',\n",
       " 'Call It What You Want',\n",
       " \"New Year's Day\",\n",
       " 'Gorgeous',\n",
       " 'Getaway Car',\n",
       " 'Text',\n",
       " 'Dress',\n",
       " 'King of My Heart',\n",
       " 'Dancing With Our Hands Tied',\n",
       " 'So It Goes',\n",
       " 'Reputation Prologue',\n",
       " \"If You're Anything Like Me Poem\",\n",
       " \"This Is Why We Can't Have Nice Things\",\n",
       " \"It's Nice to Have a Friend\",\n",
       " 'Me',\n",
       " 'Cornelia Street',\n",
       " 'You Need To Calm Down',\n",
       " 'The Man',\n",
       " 'Lover',\n",
       " 'The Archer',\n",
       " 'Death by a Thousand Cuts',\n",
       " 'Paper Rings',\n",
       " 'Afterglow\\nFormatted name',\n",
       " \"Soon You'll Get Better\",\n",
       " 'I Forgot That You Existed',\n",
       " 'Daylight\\nFormatted name',\n",
       " 'Miss Americana The Heartbreak Prince',\n",
       " 'Cruel Summer',\n",
       " 'London Boy',\n",
       " 'False God',\n",
       " 'I Think He Knows',\n",
       " 'The Last Great American Dynasty',\n",
       " 'This Is Me Trying',\n",
       " 'Epiphany',\n",
       " 'My Tears Ricochet',\n",
       " 'Exile',\n",
       " 'Mirror Ball',\n",
       " 'seven\\nFormatted name',\n",
       " 'Peace',\n",
       " \"The 1\\n\\nHowever, considering it's likely a song title, a more plausible formatted name could be\",\n",
       " 'Cardigan',\n",
       " 'Betty',\n",
       " 'Invisible String',\n",
       " 'August',\n",
       " 'Hoax',\n",
       " 'Mad Woman',\n",
       " 'Illicit Affairs',\n",
       " 'This Is The Damn Season',\n",
       " 'Evermore',\n",
       " 'Happiness',\n",
       " 'Tolerate It',\n",
       " 'Willow',\n",
       " 'Marjorie',\n",
       " 'Ivy',\n",
       " 'Dorothea',\n",
       " 'Closure',\n",
       " 'Cowboy Like Me',\n",
       " 'Long Story Short',\n",
       " 'Gold Rush',\n",
       " 'Nobody No Crime',\n",
       " 'Champagne Problems',\n",
       " 'Coney Island']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_name_safecopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "652ba821-d312-413f-aa46-bb7aad24e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Midnight Rain', 'Maroon', 'Labyrinth', \"You're On Your Own Kid\", 'Snow On The Beach', 'Question', 'Vigilante Shit', 'Karma', 'Sweet Nothing', 'Bejeweled', 'Anti Hero', 'Mastermind', 'Lavender Haze', 'Come Back Be Here', 'I Almost Do', 'Treacherous', 'The Last Time', 'All Too Well', 'State of Grace', 'Stay Stay Stay', 'Everything Has Changed', 'Starlight', 'The Lucky One', 'Holy Ground', 'WeAreNeverEverGettingBackTogether', 'Red', 'Sad Beautiful Tragic', 'Begin Again', 'I Knew You Were Trouble', '22 (or Twenty-Two) \\n\\nSince \"22\" is a number, it can be either written as is or spelled out as \"Twenty-Two\". Without more context, it\\'s difficult to determine which format is more suitable. However, in the context of song titles, it\\'s common to see numbers written as is, so \"22\" is a reasonable choice.', 'Girl at Home', 'The Moment I Knew', 'Bad Blood', 'Blank Space', 'I Know Places', 'This Love', 'Out Of The Woods', '', 'Welcome to New York', 'All You Had to Do Was Stay', 'Shake It Off', 'Style', '1989 Booklet', 'I Wish You Would', 'Clean', 'How You Get The Girl', 'I Did Something Bad', 'Ready for It', 'Delicate', \"Don't Blame Me\", 'Why She Disappeared Poem', 'Look What You Made Me Do', 'End Game', 'Call It What You Want', \"New Year's Day\", 'Gorgeous', 'Getaway Car', 'Text', 'Dress', 'King of My Heart', 'Dancing With Our Hands Tied', 'So It Goes', 'Reputation Prologue', \"If You're Anything Like Me Poem\", \"This Is Why We Can't Have Nice Things\", \"It's Nice to Have a Friend\", 'Me', 'Cornelia Street', 'You Need To Calm Down', 'The Man', 'Lover', 'The Archer', 'Death by a Thousand Cuts', 'Paper Rings', 'Afterglow', \"Soon You'll Get Better\", 'I Forgot That You Existed', 'Daylight', 'Miss Americana The Heartbreak Prince', 'Cruel Summer', 'London Boy', 'False God', 'I Think He Knows', 'The Last Great American Dynasty', 'This Is Me Trying', 'Epiphany', 'My Tears Ricochet', 'Exile', 'Mirror Ball', 'seven', 'Peace', \"The 1\\n\\nHowever, considering it's likely a song title, a more plausible formatted name could be\", 'Cardigan', 'Betty', 'Invisible String', 'August', 'Hoax', 'Mad Woman', 'Illicit Affairs', 'This Is The Damn Season', 'Evermore', 'Happiness', 'Tolerate It', 'Willow', 'Marjorie', 'Ivy', 'Dorothea', 'Closure', 'Cowboy Like Me', 'Long Story Short', 'Gold Rush', 'Nobody No Crime', 'Champagne Problems', 'Coney Island']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(formatted_name)):\n",
    "    if 'Formatted name' in formatted_name[i]: formatted_name[i] = formatted_name[i].replace('Formatted name', '').strip()\n",
    "print(formatted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f70dc0dc-9c33-47db-9b0a-831908615d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1738882d-cae6-4e94-b0cb-5d62d8f5b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            MidnightRain\n",
       "1                  Maroon\n",
       "2               Labyrinth\n",
       "3      YoureOnYourOwn_Kid\n",
       "4          SnowOnTheBeach\n",
       "              ...        \n",
       "109        longstoryshort\n",
       "110              goldrush\n",
       "111        nobody_nocrime\n",
       "112     champagneproblems\n",
       "113           coneyisland\n",
       "Name: Song_Name, Length: 114, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_song_df['Song_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c60b3ecb-ee6a-4f61-b64d-59d222e7e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_song_df.insert(2, 'Formatted_name', formatted_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ebed16f-019d-4fff-a5b8-8c2518d697f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_song_df.to_csv('song_names_formatted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45c3c2-8108-48e1-ab4e-6118b2657839",
   "metadata": {},
   "source": [
    "### Sentiment analysis using few shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba0a9a-f795-46df-8818-103e3ee4e710",
   "metadata": {},
   "source": [
    "This part uses prompting techniques discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed4cab3-c644-4617-8a3a-780ed0be08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#llm = ChatGroq(model=\"llama-3.3-70b-versatile\") \n",
    "llm = ChatGroq(model = \"llama3-70b-8192\")\n",
    "\n",
    "def few_shot_sentiment_classification(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Classify the sentiment into primary and sub-category without any explanation. Use primary categories as Romantic, Non-Romantic. If primary category is Romantic use secondary categories as Heartbreak/Break-up, Romantic Optimism. If primary category is non-Romantic then use Introspection and Stories.\n",
    "        \n",
    "        Examples:\n",
    "        Text: There I was again tonight Forcing laughter, faking smiles Same old tired, lonely place Walls of insincerity Shifting eyes and vacancy Vanished when I saw your face All I can say is it was enchanting to meet you\n",
    "        Category: Romantic, Romantic Optimism\n",
    "        \n",
    "        Text: I don't like your little games Don't like your tilted stage The role you made me play Of the fool, no, I don't like you I don't like your perfect crime How you laugh when you lie You said the gun was mine Isn't cool, no, I don't like you (Oh)\n",
    "        Category: Romantic, Heartbreak/Break-up\n",
    "        \n",
    "        Text: And I chose you The one I was dancing with In New York, no shoes Looked up at the sky and it was The burgundy on my t-shirt When you splashed your wine into me And how the blood rushed into my cheeks So scarlet, it was\n",
    "        Category: Romantic, Heartbreak/Break-up\n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Category:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    result = result.strip()\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d6d073-d737-4ba0-b09e-ebab4521ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Romantic Optimism')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Non-Romantic', ' Introspection')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n",
      "('Romantic', ' Heartbreak/Break-up')\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "song_sentiment_primary = []\n",
    "song_sentiment_secondary = []\n",
    "song_text = []\n",
    "song_names_list = []\n",
    "for an_album in filter_albums(df)['Albums'].tolist():\n",
    "    album_path = os.path.join(datapath,'Albums', an_album)\n",
    "    if os.path.exists(album_path): \n",
    "        song_names = os.listdir(album_path)        \n",
    "        for name in song_names:\n",
    "            song_names_list.append(name.replace(\".txt\", ''))\n",
    "            song_path = os.path.join(album_path,name)\n",
    "            f = open(song_path, \"r\")\n",
    "            test_text = f.read()\n",
    "            sentiment_primary, sentiment_secondary = few_shot_sentiment_classification(test_text).split(',')\n",
    "            print(f\"{sentiment_primary, sentiment_secondary}\\n\")\n",
    "            print('-------------------------')\n",
    "            song_sentiment_primary.append(sentiment_primary)\n",
    "            song_sentiment_secondary.append(sentiment_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcfa9902-13f3-49da-81c9-61441ca8d7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "print(len(song_sentiment_primary))\n",
    "print(len(song_sentiment_secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59eb4caa-8d5b-4831-8729-8db1f74990b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Formatted_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>MidnightRain</td>\n",
       "      <td>Midnight Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Maroon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>Labyrinth</td>\n",
       "      <td>Labyrinth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>YoureOnYourOwn_Kid</td>\n",
       "      <td>You're On Your Own Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>SnowOnTheBeach</td>\n",
       "      <td>Snow On The Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>longstoryshort</td>\n",
       "      <td>Long Story Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>goldrush</td>\n",
       "      <td>Gold Rush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>nobody_nocrime</td>\n",
       "      <td>Nobody No Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>champagneproblems</td>\n",
       "      <td>Champagne Problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>coneyisland</td>\n",
       "      <td>Coney Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Album           Song_Name          Formatted_name\n",
       "0    Midnights        MidnightRain           Midnight Rain\n",
       "1    Midnights              Maroon                  Maroon\n",
       "2    Midnights           Labyrinth               Labyrinth\n",
       "3    Midnights  YoureOnYourOwn_Kid  You're On Your Own Kid\n",
       "4    Midnights      SnowOnTheBeach       Snow On The Beach\n",
       "..         ...                 ...                     ...\n",
       "109   Evermore      longstoryshort        Long Story Short\n",
       "110   Evermore            goldrush               Gold Rush\n",
       "111   Evermore      nobody_nocrime         Nobody No Crime\n",
       "112   Evermore   champagneproblems      Champagne Problems\n",
       "113   Evermore         coneyisland            Coney Island\n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c935ca6d-adab-4ef2-8dd4-00178b080dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_song_df.insert(2, 'Song_sentiment_primary', song_sentiment_primary)\n",
    "album_song_df.insert(3, 'Song_sentiment_secondary', song_sentiment_secondary)\n",
    "album_song_df.to_csv('song_names_formatted_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c18dafe-4bce-44f2-9d76-88d59f985b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Album           Song_Name Song_sentiment_primary  \\\n",
      "0    Midnights        MidnightRain               Romantic   \n",
      "1    Midnights              Maroon               Romantic   \n",
      "2    Midnights           Labyrinth               Romantic   \n",
      "3    Midnights  YoureOnYourOwn_Kid               Romantic   \n",
      "4    Midnights      SnowOnTheBeach               Romantic   \n",
      "..         ...                 ...                    ...   \n",
      "109   Evermore      longstoryshort               Romantic   \n",
      "110   Evermore            goldrush               Romantic   \n",
      "111   Evermore      nobody_nocrime           Non-Romantic   \n",
      "112   Evermore   champagneproblems               Romantic   \n",
      "113   Evermore         coneyisland               Romantic   \n",
      "\n",
      "    Song_sentiment_secondary          Formatted_name  \n",
      "0        Heartbreak/Break-up           Midnight Rain  \n",
      "1        Heartbreak/Break-up                  Maroon  \n",
      "2          Romantic Optimism               Labyrinth  \n",
      "3        Heartbreak/Break-up  You're On Your Own Kid  \n",
      "4          Romantic Optimism       Snow On The Beach  \n",
      "..                       ...                     ...  \n",
      "109        Romantic Optimism        Long Story Short  \n",
      "110      Heartbreak/Break-up               Gold Rush  \n",
      "111            Introspection         Nobody No Crime  \n",
      "112      Heartbreak/Break-up      Champagne Problems  \n",
      "113      Heartbreak/Break-up            Coney Island  \n",
      "\n",
      "[114 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(album_song_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "130dcba9-2fe5-4622-a310-45b84f1938a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Song_sentiment_primary</th>\n",
       "      <th>Song_sentiment_secondary</th>\n",
       "      <th>Formatted_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>MidnightRain</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>Midnight Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>Maroon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>Labyrinth</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Romantic Optimism</td>\n",
       "      <td>Labyrinth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>YoureOnYourOwn_Kid</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>You're On Your Own Kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>SnowOnTheBeach</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Romantic Optimism</td>\n",
       "      <td>Snow On The Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>longstoryshort</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Romantic Optimism</td>\n",
       "      <td>Long Story Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>goldrush</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>Gold Rush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>nobody_nocrime</td>\n",
       "      <td>Non-Romantic</td>\n",
       "      <td>Introspection</td>\n",
       "      <td>Nobody No Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>champagneproblems</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>Champagne Problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Evermore</td>\n",
       "      <td>coneyisland</td>\n",
       "      <td>Romantic</td>\n",
       "      <td>Heartbreak/Break-up</td>\n",
       "      <td>Coney Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Album           Song_Name Song_sentiment_primary  \\\n",
       "0    Midnights        MidnightRain               Romantic   \n",
       "1    Midnights              Maroon               Romantic   \n",
       "2    Midnights           Labyrinth               Romantic   \n",
       "3    Midnights  YoureOnYourOwn_Kid               Romantic   \n",
       "4    Midnights      SnowOnTheBeach               Romantic   \n",
       "..         ...                 ...                    ...   \n",
       "109   Evermore      longstoryshort               Romantic   \n",
       "110   Evermore            goldrush               Romantic   \n",
       "111   Evermore      nobody_nocrime           Non-Romantic   \n",
       "112   Evermore   champagneproblems               Romantic   \n",
       "113   Evermore         coneyisland               Romantic   \n",
       "\n",
       "    Song_sentiment_secondary          Formatted_name  \n",
       "0        Heartbreak/Break-up           Midnight Rain  \n",
       "1        Heartbreak/Break-up                  Maroon  \n",
       "2          Romantic Optimism               Labyrinth  \n",
       "3        Heartbreak/Break-up  You're On Your Own Kid  \n",
       "4          Romantic Optimism       Snow On The Beach  \n",
       "..                       ...                     ...  \n",
       "109        Romantic Optimism        Long Story Short  \n",
       "110      Heartbreak/Break-up               Gold Rush  \n",
       "111            Introspection         Nobody No Crime  \n",
       "112      Heartbreak/Break-up      Champagne Problems  \n",
       "113      Heartbreak/Break-up            Coney Island  \n",
       "\n",
       "[114 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4b32996-355c-4c4c-a6e0-f360fa355600",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_column'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#album_song_df.insert(4, 'test_column', album_song_df['Song_sentiment'])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m album_song_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_column\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43malbum_song_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence/Pride\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m album_song_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_column\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(album_song_df.test_column.isin(['Confidence/Pride']))\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/genai/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_column'"
     ]
    }
   ],
   "source": [
    "#album_song_df.insert(4, 'test_column', album_song_df['Song_sentiment'])\n",
    "\n",
    "#album_song_df['test_column'] = album_song_df['test_column'].replace({'Confidence/Pride':'Confidence'})\n",
    "#album_song_df['test_column'].unique()\n",
    "#print(album_song_df.test_column.isin(['Confidence/Pride']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5223187-f905-4a70-a235-a3c8ef2e778a",
   "metadata": {},
   "source": [
    "#### Let's read the dataframes and combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9485c4c-0cdf-44ca-bb46-4c7d7e8735cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('song_names_formatted_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44115b4c-88cc-4054-9ac1-855b0fa0bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Album               Song_name primary_sentiment   secondary_sentiment\n",
      "0    Midnights           Midnight Rain          Romantic   Heartbreak/Break-up\n",
      "1    Midnights                  Maroon          Romantic   Heartbreak/Break-up\n",
      "2    Midnights               Labyrinth          Romantic     Romantic Optimism\n",
      "3    Midnights  You're On Your Own Kid          Romantic   Heartbreak/Break-up\n",
      "4    Midnights       Snow On The Beach          Romantic     Romantic Optimism\n",
      "..         ...                     ...               ...                   ...\n",
      "109   Evermore        Long Story Short          Romantic     Romantic Optimism\n",
      "110   Evermore               Gold Rush          Romantic   Heartbreak/Break-up\n",
      "111   Evermore         Nobody No Crime      Non-Romantic         Introspection\n",
      "112   Evermore      Champagne Problems          Romantic   Heartbreak/Break-up\n",
      "113   Evermore            Coney Island          Romantic   Heartbreak/Break-up\n",
      "\n",
      "[114 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('song_names_formatted.csv')\n",
    "df_merged = pd.DataFrame(columns = [\"Album\", \"Song_name\", \"primary_sentiment\", \"secondary_sentiment\"])\n",
    "\n",
    "df_merged[\"Album\"] = df2['Album']\n",
    "df_merged[\"Song_name\"] = df2['Formatted_name']\n",
    "df_merged[\"primary_sentiment\"] = df1['Song_sentiment_primary']\n",
    "df_merged[\"secondary_sentiment\"] = df1['Song_sentiment_secondary']\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "481917fd-6023-43f4-92de-74298ce2246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219d63c-c603-44ff-acd2-76593560e045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
