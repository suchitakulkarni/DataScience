# Default configuration for scientific paper pipeline

# Data Collection Settings
collection:
  rate_limit: 1.0  # seconds between requests
  max_papers_per_source: 100
  days_back: 90
  sources:
    - arxiv
    - inspire

# Model Configuration  
models:
  ollama:
    model_name: "llama3.2:3b"
    temperature: 0.3
    num_predict: 200
    timeout: 30
  
  embedding:
    model_name: "all-MiniLM-L6-v2"
    batch_size: 32
    normalize_embeddings: true

# Analysis Settings
analysis:
  clustering:
    n_neighbors: 15
    min_cluster_size: 3
    umap_components: 2
    metric: "cosine"
    
  text_processing:
    max_features: 100
    stop_words: "english"
    min_question_length: 10
    max_questions_per_paper: 3
    max_methods_per_paper: 5

# Output Configuration
output:
  base_dir: "output"
  save_embeddings: true
  save_plots: true
  plot_dpi: 300
  
# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null  # Set to filename to enable file logging

# External APIs
apis:
  arxiv:
    base_url: "http://export.arxiv.org/api/query"
    max_retries: 3
    
  inspire:
    base_url: "https://inspirehep.net/api/literature"
    max_retries: 3
    max_results: 1000

# Resource Limits
resources:
  max_memory_gb: 8
  max_concurrent_requests: 5
  embedding_cache_size: 1000
